{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ed0f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e937d383",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #if you have a GPU with CUDA installed, this may speed up computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb42e99",
   "metadata": {},
   "source": [
    "Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c452cd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read training data and partition it in train and validation files\n",
    "df_train = pd.read_csv('../data/train.csv', dtype={'author': np.int64, 'hindex': np.float32})\n",
    "n_train = df_train.shape[0]\n",
    "\n",
    "msk = np.random.rand(len(df_train)) < 0.8\n",
    "\n",
    "internal_train = df_train[msk]\n",
    "internal_train.to_csv('../data/internal-train.csv')\n",
    "internal_validation = df_train[~msk]\n",
    "internal_validation.to_csv('../data/internal-validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae3f81b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1036332</th>\n",
       "      <td>-0.025803</td>\n",
       "      <td>0.449338</td>\n",
       "      <td>-0.130984</td>\n",
       "      <td>1.176001</td>\n",
       "      <td>-0.210165</td>\n",
       "      <td>-1.066286</td>\n",
       "      <td>0.026156</td>\n",
       "      <td>-0.777965</td>\n",
       "      <td>0.432119</td>\n",
       "      <td>0.765542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625622</td>\n",
       "      <td>-0.095299</td>\n",
       "      <td>0.823723</td>\n",
       "      <td>-0.586748</td>\n",
       "      <td>1.241237</td>\n",
       "      <td>0.461630</td>\n",
       "      <td>-0.136655</td>\n",
       "      <td>0.191903</td>\n",
       "      <td>0.788927</td>\n",
       "      <td>-0.657276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101850</th>\n",
       "      <td>0.324045</td>\n",
       "      <td>0.031472</td>\n",
       "      <td>-0.318788</td>\n",
       "      <td>0.045695</td>\n",
       "      <td>0.675653</td>\n",
       "      <td>0.589153</td>\n",
       "      <td>-0.145144</td>\n",
       "      <td>-0.873704</td>\n",
       "      <td>0.348498</td>\n",
       "      <td>0.480307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100493</td>\n",
       "      <td>0.339010</td>\n",
       "      <td>0.449462</td>\n",
       "      <td>-0.632242</td>\n",
       "      <td>0.087819</td>\n",
       "      <td>-0.165578</td>\n",
       "      <td>0.260031</td>\n",
       "      <td>0.524244</td>\n",
       "      <td>-0.616389</td>\n",
       "      <td>-0.184688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336878</th>\n",
       "      <td>0.046531</td>\n",
       "      <td>-0.258634</td>\n",
       "      <td>0.113372</td>\n",
       "      <td>0.500867</td>\n",
       "      <td>0.190693</td>\n",
       "      <td>-0.483764</td>\n",
       "      <td>-0.042357</td>\n",
       "      <td>-0.324904</td>\n",
       "      <td>0.652467</td>\n",
       "      <td>0.358866</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.172582</td>\n",
       "      <td>-0.016618</td>\n",
       "      <td>0.345227</td>\n",
       "      <td>-0.505127</td>\n",
       "      <td>0.498401</td>\n",
       "      <td>0.801240</td>\n",
       "      <td>0.257806</td>\n",
       "      <td>-0.576735</td>\n",
       "      <td>0.151219</td>\n",
       "      <td>-0.221204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515524</th>\n",
       "      <td>0.112803</td>\n",
       "      <td>-0.625676</td>\n",
       "      <td>0.041467</td>\n",
       "      <td>0.486069</td>\n",
       "      <td>0.868460</td>\n",
       "      <td>0.553456</td>\n",
       "      <td>-0.137142</td>\n",
       "      <td>-0.596160</td>\n",
       "      <td>-0.727390</td>\n",
       "      <td>0.086116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.433929</td>\n",
       "      <td>-0.189008</td>\n",
       "      <td>0.136833</td>\n",
       "      <td>-0.999479</td>\n",
       "      <td>-0.062883</td>\n",
       "      <td>1.002005</td>\n",
       "      <td>0.897219</td>\n",
       "      <td>-0.697862</td>\n",
       "      <td>-0.084246</td>\n",
       "      <td>0.258323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606427</th>\n",
       "      <td>0.540616</td>\n",
       "      <td>-0.197666</td>\n",
       "      <td>-0.031343</td>\n",
       "      <td>0.874454</td>\n",
       "      <td>0.397556</td>\n",
       "      <td>-0.045367</td>\n",
       "      <td>-0.392079</td>\n",
       "      <td>-1.022359</td>\n",
       "      <td>0.624348</td>\n",
       "      <td>0.319048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875712</td>\n",
       "      <td>-0.629394</td>\n",
       "      <td>0.796365</td>\n",
       "      <td>-0.668456</td>\n",
       "      <td>-0.298803</td>\n",
       "      <td>0.162881</td>\n",
       "      <td>0.254460</td>\n",
       "      <td>-0.223389</td>\n",
       "      <td>0.320299</td>\n",
       "      <td>0.087225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                1         2         3         4         5         6    \\\n",
       "author_id                                                               \n",
       "1036332   -0.025803  0.449338 -0.130984  1.176001 -0.210165 -1.066286   \n",
       "1101850    0.324045  0.031472 -0.318788  0.045695  0.675653  0.589153   \n",
       "1336878    0.046531 -0.258634  0.113372  0.500867  0.190693 -0.483764   \n",
       "1515524    0.112803 -0.625676  0.041467  0.486069  0.868460  0.553456   \n",
       "1606427    0.540616 -0.197666 -0.031343  0.874454  0.397556 -0.045367   \n",
       "\n",
       "                7         8         9         10   ...       119       120  \\\n",
       "author_id                                          ...                       \n",
       "1036332    0.026156 -0.777965  0.432119  0.765542  ...  0.625622 -0.095299   \n",
       "1101850   -0.145144 -0.873704  0.348498  0.480307  ...  0.100493  0.339010   \n",
       "1336878   -0.042357 -0.324904  0.652467  0.358866  ... -0.172582 -0.016618   \n",
       "1515524   -0.137142 -0.596160 -0.727390  0.086116  ...  0.433929 -0.189008   \n",
       "1606427   -0.392079 -1.022359  0.624348  0.319048  ...  0.875712 -0.629394   \n",
       "\n",
       "                121       122       123       124       125       126  \\\n",
       "author_id                                                               \n",
       "1036332    0.823723 -0.586748  1.241237  0.461630 -0.136655  0.191903   \n",
       "1101850    0.449462 -0.632242  0.087819 -0.165578  0.260031  0.524244   \n",
       "1336878    0.345227 -0.505127  0.498401  0.801240  0.257806 -0.576735   \n",
       "1515524    0.136833 -0.999479 -0.062883  1.002005  0.897219 -0.697862   \n",
       "1606427    0.796365 -0.668456 -0.298803  0.162881  0.254460 -0.223389   \n",
       "\n",
       "                127       128  \n",
       "author_id                      \n",
       "1036332    0.788927 -0.657276  \n",
       "1101850   -0.616389 -0.184688  \n",
       "1336878    0.151219 -0.221204  \n",
       "1515524   -0.084246  0.258323  \n",
       "1606427    0.320299  0.087225  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the pre-processed features    \n",
    "df_features = pd.read_csv('../data/node-embeddings/deepwalk-128.emb', header=None, skiprows=1, delimiter=' ')\n",
    "df_features.rename(columns={0 :'author_id'}, inplace=True)\n",
    "df_features.set_index('author_id', inplace=True)\n",
    "df_features.sort_index(inplace=True)\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91a136e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuthorDataset(Dataset):\n",
    "    # The mapping file maps an author to its h-index\n",
    "    def __init__(self, mapping_file):\n",
    "        self.author_map = pd.read_csv(mapping_file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.author_map)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the author id and its h-index\n",
    "        author_id = self.author_map.iloc[idx, 1]\n",
    "        h_index = self.author_map.iloc[idx, 2].astype(np.float32)\n",
    "        features = df_features.loc[author_id,:].to_numpy(dtype=np.float32)\n",
    "        return features, h_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a5dcb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_input, n_hidden1, n_hidden2, n_output):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(n_input, n_hidden1)\n",
    "        self.fc2 = torch.nn.Linear(n_hidden1, n_hidden2)\n",
    "        self.output = torch.nn.Linear(n_hidden2, n_output)  \n",
    "        \n",
    "    def forward(self, x, verbose=False):\n",
    "        print(len(self.fcs))\n",
    "        for fc in self.fcs:\n",
    "            print(\"test\")\n",
    "            x = fc(x)\n",
    "            x = F.relu(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b5c426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    log_interval=100\n",
    "    model.train() #set model in train mode\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        # MSE loss is used in this case\n",
    "        loss = F.mse_loss(output, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "def test(model, device, test_loader):\n",
    "    model.eval() #set model in test mode\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.mse_loss(output, target, reduction=\"sum\").item()  # sum up batch loss\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: MSE loss on test set: {:.4f}\\n'.format(\n",
    "        test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ead20479",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AuthorDataset('../data/internal-train.csv')\n",
    "validation_dataset = AuthorDataset('../data/internal-validation.csv')\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=64,shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset,batch_size=1000,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0d50eed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (output): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size = df_features.shape[1]\n",
    "hidden = [256, 256]\n",
    "output_size = 1\n",
    "\n",
    "model = MLP(input_size, hidden, output_size)\n",
    "model.to(device)\n",
    "#sgd_optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "adam_optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4db08c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7c8e00c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../data/test.csv', index_col=0, dtype={'author': np.int64, 'hindex': np.float32}, delimiter=',')\n",
    "\n",
    "model.eval()\n",
    "for i, row in df_test.iterrows():\n",
    "    author_id = row['author']\n",
    "    features = df_features.loc[author_id,:].to_numpy(dtype=np.float32)\n",
    "    h_index = int(round(model(torch.from_numpy(features)).item()))\n",
    "    df_test.at[i, 'hindex']  = h_index\n",
    "\n",
    "df_test = df_test.astype({'hindex':np.int32})\n",
    "df_test.to_csv('../data/test-completed.csv', sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
