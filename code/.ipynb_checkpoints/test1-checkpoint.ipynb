{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ed0f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e937d383",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #if you have a GPU with CUDA installed, this may speed up computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb42e99",
   "metadata": {},
   "source": [
    "Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c452cd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read training data and partition it in train and validation files\n",
    "df_train = pd.read_csv('../data/train.csv', dtype={'author': np.int64, 'hindex': np.float32})\n",
    "n_train = df_train.shape[0]\n",
    "\n",
    "msk = np.random.rand(len(df_train)) < 0.8\n",
    "\n",
    "internal_train = df_train[msk]\n",
    "internal_train.to_csv('../data/internal-train.csv')\n",
    "internal_validation = df_train[~msk]\n",
    "internal_validation.to_csv('../data/internal-validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae3f81b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>225</th>\n",
       "      <th>226</th>\n",
       "      <th>227</th>\n",
       "      <th>228</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1036332</th>\n",
       "      <td>0.19717</td>\n",
       "      <td>0.12603</td>\n",
       "      <td>-0.07933</td>\n",
       "      <td>0.02404</td>\n",
       "      <td>0.24165</td>\n",
       "      <td>0.17292</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>-0.36463</td>\n",
       "      <td>0.09118</td>\n",
       "      <td>-0.21507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.62562</td>\n",
       "      <td>-0.09530</td>\n",
       "      <td>0.82372</td>\n",
       "      <td>-0.58675</td>\n",
       "      <td>1.24124</td>\n",
       "      <td>0.46163</td>\n",
       "      <td>-0.13666</td>\n",
       "      <td>0.19190</td>\n",
       "      <td>0.78893</td>\n",
       "      <td>-0.65728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101850</th>\n",
       "      <td>0.18400</td>\n",
       "      <td>-0.08761</td>\n",
       "      <td>-0.02453</td>\n",
       "      <td>0.09629</td>\n",
       "      <td>0.13563</td>\n",
       "      <td>0.13203</td>\n",
       "      <td>0.08129</td>\n",
       "      <td>-0.39240</td>\n",
       "      <td>-0.05746</td>\n",
       "      <td>-0.18697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10049</td>\n",
       "      <td>0.33901</td>\n",
       "      <td>0.44946</td>\n",
       "      <td>-0.63224</td>\n",
       "      <td>0.08782</td>\n",
       "      <td>-0.16558</td>\n",
       "      <td>0.26003</td>\n",
       "      <td>0.52424</td>\n",
       "      <td>-0.61639</td>\n",
       "      <td>-0.18469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336878</th>\n",
       "      <td>0.15419</td>\n",
       "      <td>-0.16287</td>\n",
       "      <td>-0.00880</td>\n",
       "      <td>0.12217</td>\n",
       "      <td>0.17434</td>\n",
       "      <td>0.18038</td>\n",
       "      <td>0.08272</td>\n",
       "      <td>-0.44184</td>\n",
       "      <td>-0.06329</td>\n",
       "      <td>-0.24035</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.17258</td>\n",
       "      <td>-0.01662</td>\n",
       "      <td>0.34523</td>\n",
       "      <td>-0.50513</td>\n",
       "      <td>0.49840</td>\n",
       "      <td>0.80124</td>\n",
       "      <td>0.25781</td>\n",
       "      <td>-0.57674</td>\n",
       "      <td>0.15122</td>\n",
       "      <td>-0.22120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515524</th>\n",
       "      <td>0.22254</td>\n",
       "      <td>-0.14379</td>\n",
       "      <td>-0.03459</td>\n",
       "      <td>-0.07819</td>\n",
       "      <td>0.17318</td>\n",
       "      <td>0.05151</td>\n",
       "      <td>0.00876</td>\n",
       "      <td>-0.31340</td>\n",
       "      <td>-0.12205</td>\n",
       "      <td>-0.18052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.43393</td>\n",
       "      <td>-0.18901</td>\n",
       "      <td>0.13683</td>\n",
       "      <td>-0.99948</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>1.00201</td>\n",
       "      <td>0.89722</td>\n",
       "      <td>-0.69786</td>\n",
       "      <td>-0.08425</td>\n",
       "      <td>0.25832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606427</th>\n",
       "      <td>0.25398</td>\n",
       "      <td>-0.17235</td>\n",
       "      <td>-0.03324</td>\n",
       "      <td>0.18430</td>\n",
       "      <td>0.24849</td>\n",
       "      <td>0.18632</td>\n",
       "      <td>0.12979</td>\n",
       "      <td>-0.61093</td>\n",
       "      <td>0.05607</td>\n",
       "      <td>-0.22261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.87571</td>\n",
       "      <td>-0.62939</td>\n",
       "      <td>0.79637</td>\n",
       "      <td>-0.66846</td>\n",
       "      <td>-0.29880</td>\n",
       "      <td>0.16288</td>\n",
       "      <td>0.25446</td>\n",
       "      <td>-0.22339</td>\n",
       "      <td>0.32030</td>\n",
       "      <td>0.08723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 228 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               1        2        3        4        5        6        7    \\\n",
       "author_id                                                                  \n",
       "1036332    0.19717  0.12603 -0.07933  0.02404  0.24165  0.17292  0.01000   \n",
       "1101850    0.18400 -0.08761 -0.02453  0.09629  0.13563  0.13203  0.08129   \n",
       "1336878    0.15419 -0.16287 -0.00880  0.12217  0.17434  0.18038  0.08272   \n",
       "1515524    0.22254 -0.14379 -0.03459 -0.07819  0.17318  0.05151  0.00876   \n",
       "1606427    0.25398 -0.17235 -0.03324  0.18430  0.24849  0.18632  0.12979   \n",
       "\n",
       "               8        9        10   ...      219      220      221      222  \\\n",
       "author_id                             ...                                       \n",
       "1036332   -0.36463  0.09118 -0.21507  ...  0.62562 -0.09530  0.82372 -0.58675   \n",
       "1101850   -0.39240 -0.05746 -0.18697  ...  0.10049  0.33901  0.44946 -0.63224   \n",
       "1336878   -0.44184 -0.06329 -0.24035  ... -0.17258 -0.01662  0.34523 -0.50513   \n",
       "1515524   -0.31340 -0.12205 -0.18052  ...  0.43393 -0.18901  0.13683 -0.99948   \n",
       "1606427   -0.61093  0.05607 -0.22261  ...  0.87571 -0.62939  0.79637 -0.66846   \n",
       "\n",
       "               223      224      225      226      227      228  \n",
       "author_id                                                        \n",
       "1036332    1.24124  0.46163 -0.13666  0.19190  0.78893 -0.65728  \n",
       "1101850    0.08782 -0.16558  0.26003  0.52424 -0.61639 -0.18469  \n",
       "1336878    0.49840  0.80124  0.25781 -0.57674  0.15122 -0.22120  \n",
       "1515524   -0.06288  1.00201  0.89722 -0.69786 -0.08425  0.25832  \n",
       "1606427   -0.29880  0.16288  0.25446 -0.22339  0.32030  0.08723  \n",
       "\n",
       "[5 rows x 228 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the pre-processed features    \n",
    "df_features = pd.read_csv('../data/author-embeddings/glove-twitter-100-deepwalk-128.csv', header=None)\n",
    "df_features.rename(columns={0 :'author_id'}, inplace=True)\n",
    "df_features.set_index('author_id', inplace=True)\n",
    "df_features.sort_index(inplace=True)\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91a136e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuthorDataset(Dataset):\n",
    "    # The mapping file maps an author to its h-index\n",
    "    def __init__(self, mapping_file):\n",
    "        self.author_map = pd.read_csv(mapping_file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.author_map)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the author id and its h-index\n",
    "        author_id = self.author_map.iloc[idx, 1]\n",
    "        h_index = self.author_map.iloc[idx, 2].astype(np.float32)\n",
    "        features = df_features.loc[author_id,:].to_numpy(dtype=np.float32)\n",
    "        return features, h_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1a5dcb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_input, n_hidden, n_output):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(n_input, n_hidden)  \n",
    "        self.fc2 = torch.nn.Linear(n_hidden, n_hidden)\n",
    "        self.output = torch.nn.Linear(n_hidden, n_output)  \n",
    "        \n",
    "    def forward(self, x, verbose=False):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0b5c426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    log_interval=100\n",
    "    model.train() #set model in train mode\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        # MSE loss is used in this case\n",
    "        loss = F.mse_loss(output, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "def test(model, device, test_loader):\n",
    "    model.eval() #set model in test mode\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.mse_loss(output, target, reduction=\"sum\").item()  # sum up batch loss\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: MSE loss on test set: {:.4f}\\n'.format(\n",
    "        test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ead20479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34928\n"
     ]
    }
   ],
   "source": [
    "train_dataset = AuthorDataset('../data/internal-train.csv')\n",
    "validation_dataset = AuthorDataset('../data/internal-validation.csv')\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=64,shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset,batch_size=1000,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d50eed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5551/3667007599.py:10: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(output, target)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/139313 (0%)]\tLoss: 136.834686\n",
      "Train Epoch: 0 [6400/139313 (5%)]\tLoss: 204.764206\n",
      "Train Epoch: 0 [12800/139313 (9%)]\tLoss: 110.726791\n",
      "Train Epoch: 0 [19200/139313 (14%)]\tLoss: 299.557251\n",
      "Train Epoch: 0 [25600/139313 (18%)]\tLoss: 97.260201\n",
      "Train Epoch: 0 [32000/139313 (23%)]\tLoss: 163.561798\n",
      "Train Epoch: 0 [38400/139313 (28%)]\tLoss: 86.347214\n",
      "Train Epoch: 0 [44800/139313 (32%)]\tLoss: 196.537964\n",
      "Train Epoch: 0 [51200/139313 (37%)]\tLoss: 127.320312\n",
      "Train Epoch: 0 [57600/139313 (41%)]\tLoss: 95.478394\n",
      "Train Epoch: 0 [64000/139313 (46%)]\tLoss: 133.546860\n",
      "Train Epoch: 0 [70400/139313 (51%)]\tLoss: 128.108582\n",
      "Train Epoch: 0 [76800/139313 (55%)]\tLoss: 93.910187\n",
      "Train Epoch: 0 [83200/139313 (60%)]\tLoss: 204.424347\n",
      "Train Epoch: 0 [89600/139313 (64%)]\tLoss: 138.978592\n",
      "Train Epoch: 0 [96000/139313 (69%)]\tLoss: 142.452805\n",
      "Train Epoch: 0 [102400/139313 (73%)]\tLoss: 160.477234\n",
      "Train Epoch: 0 [108800/139313 (78%)]\tLoss: 124.348274\n",
      "Train Epoch: 0 [115200/139313 (83%)]\tLoss: 130.594589\n",
      "Train Epoch: 0 [121600/139313 (87%)]\tLoss: 235.881424\n",
      "Train Epoch: 0 [128000/139313 (92%)]\tLoss: 105.816772\n",
      "Train Epoch: 0 [134400/139313 (96%)]\tLoss: 108.229019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5551/3667007599.py:10: UserWarning: Using a target size (torch.Size([49])) that is different to the input size (torch.Size([49, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(output, target)\n",
      "/tmp/ipykernel_5551/3667007599.py:26: UserWarning: Using a target size (torch.Size([1000])) that is different to the input size (torch.Size([1000, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  test_loss += F.mse_loss(output, target, reduction=\"sum\").item()  # sum up batch loss\n",
      "/tmp/ipykernel_5551/3667007599.py:26: UserWarning: Using a target size (torch.Size([928])) that is different to the input size (torch.Size([928, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  test_loss += F.mse_loss(output, target, reduction=\"sum\").item()  # sum up batch loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34928\n",
      "5582088208.0\n",
      "159817.00091617042\n",
      "\n",
      "Test set: MSE loss on test set: 159817.0009\n",
      "\n",
      "Train Epoch: 1 [0/139313 (0%)]\tLoss: 176.856216\n",
      "Train Epoch: 1 [6400/139313 (5%)]\tLoss: 146.036942\n",
      "Train Epoch: 1 [12800/139313 (9%)]\tLoss: 132.933960\n",
      "Train Epoch: 1 [19200/139313 (14%)]\tLoss: 105.440598\n",
      "Train Epoch: 1 [25600/139313 (18%)]\tLoss: 149.007462\n",
      "Train Epoch: 1 [32000/139313 (23%)]\tLoss: 77.845337\n",
      "Train Epoch: 1 [38400/139313 (28%)]\tLoss: 89.480675\n",
      "Train Epoch: 1 [44800/139313 (32%)]\tLoss: 170.107376\n",
      "Train Epoch: 1 [51200/139313 (37%)]\tLoss: 82.979691\n",
      "Train Epoch: 1 [57600/139313 (41%)]\tLoss: 130.847504\n",
      "Train Epoch: 1 [64000/139313 (46%)]\tLoss: 86.839035\n",
      "Train Epoch: 1 [70400/139313 (51%)]\tLoss: 65.536613\n",
      "Train Epoch: 1 [76800/139313 (55%)]\tLoss: 166.298752\n",
      "Train Epoch: 1 [83200/139313 (60%)]\tLoss: 238.401779\n",
      "Train Epoch: 1 [89600/139313 (64%)]\tLoss: 474.675354\n",
      "Train Epoch: 1 [96000/139313 (69%)]\tLoss: 104.977554\n"
     ]
    }
   ],
   "source": [
    "input_size = df_features.shape[1]\n",
    "n_hidden = 256\n",
    "output_size = 1\n",
    "\n",
    "model = MLP(input_size, n_hidden, output_size)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "n_epochs = 4\n",
    "\n",
    "for epoch in range(0, n_epochs):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7c8e00c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../data/test.csv', index_col=0, dtype={'author': np.int64, 'hindex': np.float32}, delimiter=',')\n",
    "\n",
    "model.eval()\n",
    "for i, row in df_test.iterrows():\n",
    "    author_id = row['author']\n",
    "    features = df_features.loc[author_id,:].to_numpy(dtype=np.float32)\n",
    "    h_index = int(round(model(torch.from_numpy(features)).item()))\n",
    "    df_test.at[i, 'hindex']  = h_index\n",
    "\n",
    "df_test = df_test.astype({'hindex':np.int32})\n",
    "df_test.to_csv('../data/test-completed.csv', sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
